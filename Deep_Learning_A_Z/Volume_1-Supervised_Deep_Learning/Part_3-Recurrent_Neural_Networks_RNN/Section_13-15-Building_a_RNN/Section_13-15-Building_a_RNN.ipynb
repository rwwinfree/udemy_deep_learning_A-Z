{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.superdatascience.com/pages/deep-learning -> course documents\n",
    "This is actually a movie created by a RNN. Additional reading: https://arstechnica.com/gaming/2016/06/an-ai-wrote-this-movie-and-its-strangely-moving/\n",
    "\n",
    "Reference: http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "The goal is to predict the trend of the Google Stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings to display more with print\n",
    "pd.options.display.max_rows = 200\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Part 1 - Data Preprocessing (Steps 1-3)\n",
    "# The RNN will only be trained on the training set. It will not see the test set until after the training is done!\n",
    "dataset_train = pd.read_csv('dataset/Google_Stock_Price_Train.csv')\n",
    "training_set = dataset_train.iloc[:,1:2].values # creates a data frame (numpy array)\n",
    "# getting the Open prices of the Google stock price\n",
    "# first : refers to all rows\n",
    "    # Do not want just a vector array. Want a 2d array for np. This means we must import an array for the number of columns.\n",
    "    # The trick is to reference 1:2 because in python the upperbound is excluded. so only column index[1] is taken but imported\n",
    "    # in the correct format (numpy array of 1 column)\n",
    "    # the .values makes it a np array\n",
    "print(type(dataset_train))\n",
    "print(type(training_set))\n",
    "\n",
    "# Feature Scaling\n",
    "\n",
    "#MinMaxScaler normalizes the data\n",
    "sc = MinMaxScaler(feature_range = (0,1), copy=True) #sc refers to scale\n",
    "#fit means that it will get the min and max and will scale the data. The transform will compute the scaled (normalized) value based on the normalization formula.\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08581368]\n",
      " [0.09701243]\n",
      " [0.09433366]\n",
      " ...\n",
      " [0.95725128]\n",
      " [0.93796041]\n",
      " [0.93688146]]\n"
     ]
    }
   ],
   "source": [
    "print(training_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "# the 60 timestep means that the model will look at time t, the previous 60 times steps and time step t. Based on those values\n",
    "# the model will try to predict the next output. \n",
    "# The value of 60 timesteps was chosen by trial and error. There are ~20 buisness days in a month so 60 timesteps is 60 buisness days (3 months)\n",
    "X_train = [] #input (60 previous days)\n",
    "y_train = [] #output (stock price for the next financial day)\n",
    "#these are lists\n",
    "\n",
    "for i in range(60, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0]) #upperbound is excluded\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "\n",
    "# y_train is the array that needs to be predicted based on the data in X_train\n",
    "# converting lists to np arrays\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08581368 0.09701243 0.09433366 ... 0.07846566 0.08034452 0.08497656]\n",
      " [0.09701243 0.09433366 0.09156187 ... 0.08034452 0.08497656 0.08627874]\n",
      " [0.09433366 0.09156187 0.07984225 ... 0.08497656 0.08627874 0.08471612]\n",
      " ...\n",
      " [0.92106928 0.92438053 0.93048218 ... 0.95475854 0.95204256 0.95163331]\n",
      " [0.92438053 0.93048218 0.9299055  ... 0.95204256 0.95163331 0.95725128]\n",
      " [0.93048218 0.9299055  0.93113327 ... 0.95163331 0.95725128 0.93796041]]\n",
      "(1198, 60)\n",
      "------------------\n",
      "Break for viewing\n",
      "------------------\n",
      "[0.08627874 0.08471612 0.07454052 ... 0.95725128 0.93796041 0.93688146]\n",
      "(1198,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_train.shape)\n",
    "print(\"------------------\")\n",
    "print(\"Break for viewing\")\n",
    "print(\"------------------\")\n",
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5\n",
    "\n",
    "# Reshaping\n",
    "# 1st argument is the np.array you want to reshape\n",
    "# the 2nd argument is the new shape we want the array to have\n",
    "# the 3rd dimension is the new indicator or number of indicators (new input dimenions). \n",
    "# want 3 dimensions for X_train with the 3rd corresponding to the indicator (prediction)\n",
    "# Information for the recurrent input shapes: https://keras.io/layers/recurrent/\n",
    "# Look under the headers \"Input shapes\"\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    # 1 corresponds to the Google Open Stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.08581368]\n",
      "  [0.09701243]\n",
      "  [0.09433366]\n",
      "  ...\n",
      "  [0.07846566]\n",
      "  [0.08034452]\n",
      "  [0.08497656]]\n",
      "\n",
      " [[0.09701243]\n",
      "  [0.09433366]\n",
      "  [0.09156187]\n",
      "  ...\n",
      "  [0.08034452]\n",
      "  [0.08497656]\n",
      "  [0.08627874]]\n",
      "\n",
      " [[0.09433366]\n",
      "  [0.09156187]\n",
      "  [0.07984225]\n",
      "  ...\n",
      "  [0.08497656]\n",
      "  [0.08627874]\n",
      "  [0.08471612]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.92106928]\n",
      "  [0.92438053]\n",
      "  [0.93048218]\n",
      "  ...\n",
      "  [0.95475854]\n",
      "  [0.95204256]\n",
      "  [0.95163331]]\n",
      "\n",
      " [[0.92438053]\n",
      "  [0.93048218]\n",
      "  [0.9299055 ]\n",
      "  ...\n",
      "  [0.95204256]\n",
      "  [0.95163331]\n",
      "  [0.95725128]]\n",
      "\n",
      " [[0.93048218]\n",
      "  [0.9299055 ]\n",
      "  [0.93113327]\n",
      "  ...\n",
      "  [0.95163331]\n",
      "  [0.95725128]\n",
      "  [0.93796041]]]\n",
      "(1198, 60, 1)\n",
      "------------------\n",
      "Break for viewing\n",
      "------------------\n",
      "[0.08627874 0.08471612 0.07454052 ... 0.95725128 0.93796041 0.93688146]\n",
      "(1198,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_train.shape)\n",
    "print(\"------------------\")\n",
    "print(\"Break for viewing\")\n",
    "print(\"------------------\")\n",
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "''' Notes on reshape from Seby: https://www.udemy.com/course/deeplearning/learn/lecture/8374804#questions/5107738\n",
    "Here is how numpy reshape works.\n",
    "\n",
    "Say you have N numbers in an array. No matter what the array's shape is, you can break that down into any number of factors.\n",
    "\n",
    "Such that\n",
    "\n",
    "a*b*c = N\n",
    "\n",
    "x*y*z*w = N\n",
    "\n",
    "For example,\n",
    "\n",
    "if N is 1000,\n",
    "\n",
    "It can be shaped to\n",
    "\n",
    "(10,100)  or (100,10) or  (10,10,10)  or (1,1000)  or (1,1,1000) .\n",
    "\n",
    "Even:\n",
    "\n",
    "(25,4,10) or (8,125) etc.\n",
    "\n",
    "So, for your problem, you have 171720 numbers and you are trying to shape it into (2862,60,5).\n",
    "\n",
    "However, 2862*60*5 = 858600\n",
    "\n",
    "858600 is 5 times more than 171720, which would mean that you havent added more features into your training set first before you try and reshape it. Your X which you are trying to reshape still has only one feature.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''More Notes from Seby: https://www.udemy.com/course/deeplearning/learn/lecture/8374804#questions/3554002\n",
    "# Part 1 - Data Preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    " \n",
    "# Importing Training Set\n",
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    " \n",
    "cols = list(dataset_train)[1:5]\n",
    " \n",
    "#Preprocess data for training by removing all commas\n",
    " \n",
    "dataset_train = dataset_train[cols].astype(str)\n",
    "for i in cols:\n",
    "    for j in range(0,len(dataset_train)):\n",
    "        dataset_train[i][j] = dataset_train[i][j].replace(\",\",\"\")\n",
    " \n",
    "dataset_train = dataset_train.astype(float)\n",
    " \n",
    " \n",
    "training_set = dataset_train.as_matrix() # Using multiple predictors.\n",
    " \n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "sc = StandardScaler()\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    " \n",
    "sc_predict = StandardScaler()\n",
    " \n",
    "sc_predict.fit_transform(training_set[:,0:1])\n",
    " \n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    " \n",
    "n_future = 20  # Number of days you want to predict into the future\n",
    "n_past = 60  # Number of past days you want to use to predict the future\n",
    " \n",
    "for i in range(n_past, len(training_set_scaled) - n_future + 1):\n",
    "    X_train.append(training_set_scaled[i - n_past:i, 0:5])\n",
    "    y_train.append(training_set_scaled[i+n_future-1:i + n_future, 0])\n",
    " \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    " \n",
    "# Part 2 - Building the RNN\n",
    " \n",
    "# Import Libraries and packages from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    " \n",
    "# Initializing the RNN\n",
    "regressor = Sequential()\n",
    " \n",
    "# Adding fist LSTM layer and Drop out Regularization\n",
    "regressor.add(LSTM(units=10, return_sequences=True, input_shape=(n_past, 4)))\n",
    " \n",
    " \n",
    "# Part 3 - Adding more layers\n",
    "# Adding 2nd layer with some drop out regularization\n",
    "regressor.add(LSTM(units=4, return_sequences=False))\n",
    " \n",
    "# Output layer\n",
    "regressor.add(Dense(units=1, activation='linear'))\n",
    " \n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer='adam', loss=\"mean_squared_error\")  # Can change loss to mean-squared-error if you require.\n",
    " \n",
    "# Fitting RNN to training set using Keras Callbacks. Read Keras callbacks docs for more info.\n",
    " \n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "tb = TensorBoard('logs')\n",
    " \n",
    "history = regressor.fit(X_train, y_train, shuffle=True, epochs=100,\n",
    "                        callbacks=[es, rlr,mcp, tb], validation_split=0.2, verbose=1, batch_size=64)\n",
    " \n",
    " \n",
    "# Predicting the future.\n",
    "#--------------------------------------------------------\n",
    "# The last date for our training set is 30-Dec-2016.\n",
    "# Lets now try predicting the stocks for the dates in the test set.\n",
    " \n",
    "# The dates on our test set are:\n",
    "# 3,4,5,6,9,10,11,12,13,17,18,19,20,23,24,25,26,27,30,31-Jan-2017\n",
    " \n",
    "# Now, the latest we can predict into our test set is to the 19th since the last date on training is 30-Dec-2016. \n",
    "# 20 days into the future from the latest day in our training set is 19-Dec-2016. Right?\n",
    "# Notice that we dont have some days in our test set, what we can do is to take the last 20 samples from the training set. \n",
    "# (Remember the last sample of our training set will predict the 19th of Jan 2017, the second last will predict the 18th, etc)\n",
    " \n",
    " \n",
    "# Lets first import the test_set.\n",
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "y_true = np.array(dataset_test['Open'])\n",
    "#Trim the test set to first 12 entries (till the 19th)\n",
    "y_true = y_true[0:12]\n",
    "predictions = regressor.predict(X_train[-20:])\n",
    " \n",
    " \n",
    "# We skip the 31-Dec, 1-Jan,2-Jan, etc to compare with the test_set\n",
    "predictions_to_compare = predictions[[3,4,5,6,9,10,11,12,13,17,18,19]]\n",
    "y_pred = sc_predict.inverse_transform(predictions_to_compare)\n",
    " \n",
    " \n",
    " \n",
    "hfm, = plt.plot(y_pred, 'r', label='predicted_stock_price')\n",
    "hfm2, = plt.plot(y_true,'b', label = 'actual_stock_price')\n",
    " \n",
    "plt.legend(handles=[hfm,hfm2])\n",
    "plt.title('Predictions and Actual Price')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Stock Price Future')\n",
    "plt.savefig('graph.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    " \n",
    " \n",
    " \n",
    "hfm, = plt.plot(sc_predict.inverse_transform(y_train), 'r', label='actual_training_stock_price')\n",
    "hfm2, = plt.plot(sc_predict.inverse_transform(regressor.predict(X_train)),'b', label = 'predicted_training_stock_price')\n",
    " \n",
    "plt.legend(handles=[hfm,hfm2])\n",
    "plt.title('Predictions vs Actual Price')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Stock Price Training')\n",
    "plt.savefig('graph_training.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Building the RNN\n",
    "    # Building a LSTM\n",
    "    # Look up CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ryanwinfree/opt/anaconda3/envs/udemy4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/ryanwinfree/opt/anaconda3/envs/udemy4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/ryanwinfree/opt/anaconda3/envs/udemy4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/ryanwinfree/opt/anaconda3/envs/udemy4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/ryanwinfree/opt/anaconda3/envs/udemy4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/ryanwinfree/opt/anaconda3/envs/udemy4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Step 6\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "#print(Tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "https://www.udemy.com/course/deeplearning/learn/lecture/8374810#questions/6446750\n",
    "Please check your Tensorflow version and Keras version by typing in the Anaconda Prompt:\n",
    "\n",
    ">>python\n",
    "\n",
    ">>import keras\n",
    "\n",
    ">>import tensorflow\n",
    "\n",
    ">>keras.__version__\n",
    "\n",
    ">>tensorflow.__version\n",
    "\n",
    "\n",
    "after this, go the this web page and check if the versions your have are compatibe:\n",
    "\n",
    "https://docs.floydhub.com/guides/environments/\n",
    "\n",
    "\n",
    "For sure you will find a non compatible keras version with your tensorflow version, to correct it you have to reinstall keras:\n",
    "\n",
    "\n",
    "open new anaconda prompt:\n",
    "\n",
    ">>pip uninstall keras\n",
    "\n",
    ">>pip install keras==2.0.8 (replace the  '2.0.8' by the version number you need)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ryanwinfree/opt/anaconda3/envs/udemy4/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Step 7\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "    # represents a sequence of layers\n",
    "\n",
    "# LSTM class\n",
    "# Adding the first LSTM layer and some Dropout regularisation (added to avoid overfitting). Don't want overfitting in general\n",
    "# LSTM first layer. Need to use the LSTM class. Need to input 3 arguments\n",
    "    # number of units = number of LSTM memory cells to have in the layer. Like neurons\n",
    "    # 2nd arg. return sequences. Set to true because building a stacked LSTM. So have to return values if having multiple LSTM layers\n",
    "    # 3rd arg. input shape. The shape of the input (e.g. shape of X_train which is 3D). Only have to specify 2 of the 3 dimensions though\n",
    "        # X_train.shape[1] is the time steps\n",
    "        # 1 corresponds to the indicators (predictors)\n",
    "# Only have to specify the input shape for the first layer\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1) ))\n",
    "\n",
    "# Adding dropout regularisation\n",
    "    # standard to dropout 20%. So 20% of the neurons will be ignored in the backward and forward propegation \n",
    "    # (so 10 neurons)\n",
    "    # these are ignored each iteration of the training\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8\n",
    "# Adding a 2nd LSTM layer and some dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8\n",
    "# Adding a 3rd LSTM layer and some dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "# Adding a 4th LSTM layer and some dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = False))\n",
    "# setting return_sequences because we don't return it on the last LSTM layer? \n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9; Adding the output layer\n",
    "# Adding a fully connected layer to the last LSTM layer. Use the Dense class\n",
    "# 1 neuron for the output layer (1 in this case).\n",
    "regressor.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The framework for the RNN is complete at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ryanwinfree/opt/anaconda3/envs/udemy4/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Step 10\n",
    "# Compiling the RNN. \n",
    "# Input the optimizer (look at the keras documentation: keras.io). \n",
    "# RMSprop is usually a good optimizer to use with RNNs. However, \n",
    "# using a different one due to experimentation \n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.08581368]\n",
      "  [0.09701243]\n",
      "  [0.09433366]\n",
      "  ...\n",
      "  [0.07846566]\n",
      "  [0.08034452]\n",
      "  [0.08497656]]\n",
      "\n",
      " [[0.09701243]\n",
      "  [0.09433366]\n",
      "  [0.09156187]\n",
      "  ...\n",
      "  [0.08034452]\n",
      "  [0.08497656]\n",
      "  [0.08627874]]\n",
      "\n",
      " [[0.09433366]\n",
      "  [0.09156187]\n",
      "  [0.07984225]\n",
      "  ...\n",
      "  [0.08497656]\n",
      "  [0.08627874]\n",
      "  [0.08471612]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.92106928]\n",
      "  [0.92438053]\n",
      "  [0.93048218]\n",
      "  ...\n",
      "  [0.95475854]\n",
      "  [0.95204256]\n",
      "  [0.95163331]]\n",
      "\n",
      " [[0.92438053]\n",
      "  [0.93048218]\n",
      "  [0.9299055 ]\n",
      "  ...\n",
      "  [0.95204256]\n",
      "  [0.95163331]\n",
      "  [0.95725128]]\n",
      "\n",
      " [[0.93048218]\n",
      "  [0.9299055 ]\n",
      "  [0.93113327]\n",
      "  ...\n",
      "  [0.95163331]\n",
      "  [0.95725128]\n",
      "  [0.93796041]]]\n",
      "(1198, 60, 1)\n",
      "------------------\n",
      "Break for viewing\n",
      "------------------\n",
      "[0.08627874 0.08471612 0.07454052 ... 0.95725128 0.93796041 0.93688146]\n",
      "(1198,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_train.shape)\n",
    "print(\"------------------\")\n",
    "print(\"Break for viewing\")\n",
    "print(\"------------------\")\n",
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/105\n",
      "1198/1198 [==============================] - 23s 19ms/step - loss: 0.0460\n",
      "Epoch 2/105\n",
      "1198/1198 [==============================] - 18s 15ms/step - loss: 0.0066\n",
      "Epoch 3/105\n",
      "1198/1198 [==============================] - 18s 15ms/step - loss: 0.0056\n",
      "Epoch 4/105\n",
      "1198/1198 [==============================] - 18s 15ms/step - loss: 0.0054\n",
      "Epoch 5/105\n",
      "1198/1198 [==============================] - 18s 15ms/step - loss: 0.0046\n",
      "Epoch 6/105\n",
      "1198/1198 [==============================] - 17s 15ms/step - loss: 0.0044\n",
      "Epoch 7/105\n",
      "1198/1198 [==============================] - 18s 15ms/step - loss: 0.0046\n",
      "Epoch 8/105\n",
      "1198/1198 [==============================] - 20s 17ms/step - loss: 0.0037\n",
      "Epoch 9/105\n",
      "1198/1198 [==============================] - 19s 16ms/step - loss: 0.0046\n",
      "Epoch 10/105\n",
      "1198/1198 [==============================] - 17s 14ms/step - loss: 0.0045\n",
      "Epoch 11/105\n",
      "1198/1198 [==============================] - 17s 14ms/step - loss: 0.0039\n",
      "Epoch 12/105\n",
      "1198/1198 [==============================] - 17s 14ms/step - loss: 0.0043\n",
      "Epoch 13/105\n",
      "1198/1198 [==============================] - 17s 14ms/step - loss: 0.0043\n",
      "Epoch 14/105\n",
      "1198/1198 [==============================] - 17s 14ms/step - loss: 0.0036\n",
      "Epoch 15/105\n",
      "1198/1198 [==============================] - 17s 14ms/step - loss: 0.0043\n",
      "Epoch 16/105\n",
      "1198/1198 [==============================] - 17s 14ms/step - loss: 0.0032\n",
      "Epoch 17/105\n",
      "1198/1198 [==============================] - 18s 15ms/step - loss: 0.0036\n",
      "Epoch 18/105\n",
      "1198/1198 [==============================] - 18s 15ms/step - loss: 0.0037\n",
      "Epoch 19/105\n",
      " 448/1198 [==========>...................] - ETA: 10s - loss: 0.0036"
     ]
    }
   ],
   "source": [
    "# Step 11 (final step of part 2): Fitting the data to training set\n",
    "# Fitting the RNN to the Training Set\n",
    "# y_train = the \"ground truth\", aka the answers for the RNN\n",
    "# batch size = the batches of stock prices going into the NN at once. \n",
    "regressor.fit(X_train, y_train, epochs = 105, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Making the predictions and visulising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
