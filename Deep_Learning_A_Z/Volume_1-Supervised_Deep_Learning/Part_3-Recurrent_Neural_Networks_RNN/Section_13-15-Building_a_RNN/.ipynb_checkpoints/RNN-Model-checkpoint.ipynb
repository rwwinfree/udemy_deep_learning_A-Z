{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.superdatascience.com/pages/deep-learning -> course documents\n",
    "This is actually a movie created by a RNN. Additional reading: https://arstechnica.com/gaming/2016/06/an-ai-wrote-this-movie-and-its-strangely-moving/\n",
    "\n",
    "Reference: http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "The goal is to predict the trend of the Google Stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[0.08581368 0.09701243 0.09433366 ... 0.07846566 0.08034452 0.08497656]\n",
      " [0.09701243 0.09433366 0.09156187 ... 0.08034452 0.08497656 0.08627874]\n",
      " [0.09433366 0.09156187 0.07984225 ... 0.08497656 0.08627874 0.08471612]\n",
      " ...\n",
      " [0.92106928 0.92438053 0.93048218 ... 0.95475854 0.95204256 0.95163331]\n",
      " [0.92438053 0.93048218 0.9299055  ... 0.95204256 0.95163331 0.95725128]\n",
      " [0.93048218 0.9299055  0.93113327 ... 0.95163331 0.95725128 0.93796041]]\n",
      "\n",
      "Break for viewing\n",
      "\n",
      "[0.08627874 0.08471612 0.07454052 ... 0.95725128 0.93796041 0.93688146]\n"
     ]
    }
   ],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "# The RNN will only be trained on the training set. It will not see the test set until after the training is done!\n",
    "dataset_train = pd.read_csv('dataset/Google_Stock_Price_Train.csv')\n",
    "training_set = dataset_train.iloc[:,1:2].values # creates a data frame (numpy array)\n",
    "# getting the Open prices of the Google stock price\n",
    "# first : refers to all rows\n",
    "    # Do not want just a vector array. Want a 2d array for np. This means we must import an array for the number of columns.\n",
    "    # The trick is to reference 1:2 because in python the upperbound is excluded. so only column index[1] is taken but imported\n",
    "    # in the correct format (numpy array of 1 column)\n",
    "    # the .values makes it a np array\n",
    "print(type(dataset_train))\n",
    "print(type(training_set))\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1), copy=True)\n",
    "#fit means that it will get the min and max and will scale the data. The transform will compute the scaled (normalized) value based on the normalization formula.\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "#print(training_set_scaled)\n",
    "\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "# the 60 timestep means that the model will look at time t, the previous 60 times steps and time step t. Based on those values\n",
    "# the model will try to predict the next output. \n",
    "# The value of 60 timesteps was chosen by trial and error. There are ~20 buisness days in a month so 60 timesteps is 60 buisness days (3 months)\n",
    "X_train = []\n",
    "y_train = []\n",
    "#print(len(training_set_scaled))\n",
    "\n",
    "for i in range(60, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "\n",
    "# y_train is the array that needs to be predicted based on the data in X_train\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "print(X_train)\n",
    "print(\"\")\n",
    "print(\"Break for viewing\")\n",
    "print(\"\")\n",
    "print(y_train)\n",
    "\n",
    "# Reshaping\n",
    "# the 2nd argument is the new shape we want the array to have\n",
    "# want 3 dimensions for X_train with the 3rd corresponding to the indicator (prediction)\n",
    "# Information for the recurrent input shapes: https://keras.io/layers/recurrent/\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]), 1)\n",
    "    # 1 corresponds to the Google Open Stock Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Building the RNN\n",
    "    # Building a LSTM\n",
    "    # Look up CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Building the RNN\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "    # represents a sequence of layers\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation (added to avoid overfitting). Don't want overfitting in general\n",
    "# LSTM first layer. Need to use the LSTM class. Need to input 3 arguments\n",
    "    # number of units = number of LSTM memory cells to have in the layer. Like neurons\n",
    "    # 2nd arg. return sequences. Set to true because building a stacked LSTM. So have to return values if having multiple LSTM layers\n",
    "    # 3rd arg. input shape. The shape of the input (e.g. shape of X_train which is 3D). Only have to specify 2 of the 3 dimensions though\n",
    "        # X_train.shape[1] is the time steps\n",
    "        # 1 corresponds to the indicators (predictors)\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1) ))\n",
    "\n",
    "# Adding dropout regularisation\n",
    "    # standard to dropout 20%. So 20% of the neurons will be ignored in the backward and forward propegation (so 10 neurons)\n",
    "    # these are ignored each iteration of the training\n",
    "regressor.add(Dropout(0.2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and visulising the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
